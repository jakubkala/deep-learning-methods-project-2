{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, regularizers\n",
    "\n",
    "from data_preprocessing import one_hot_encode\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.empty((0, 32, 32, 3), int)\n",
    "y_train = np.empty((0, 10), int)\n",
    "\n",
    "\n",
    "for i in range(1, 6):\n",
    "    raw_data = unpickle(f'../data/data_batch_{i}')\n",
    "    X_tmp = raw_data[b'data']\n",
    "    X_tmp = np.reshape(X_tmp, (-1, 32, 32, 3), order='F').transpose(0, 2, 1, 3)\n",
    "    y_tmp = np.array(raw_data[b'labels'])\n",
    "    X_train = np.append(X_train, X_tmp, axis=0)\n",
    "    y_train = np.append(y_train, y_tmp)\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "simple_cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "simple_cnn.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "simple_cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "simple_cnn.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "simple_cnn.add(layers.Flatten())\n",
    "simple_cnn.add(layers.Dense(64, activation='relu'))\n",
    "simple_cnn.add(layers.Dense(64, activation='relu'))\n",
    "simple_cnn.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 229,194\n",
      "Trainable params: 229,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/50\n",
      "47500/47500 [==============================] - 47s 998us/sample - loss: 2.2510 - accuracy: 0.1991 - val_loss: 1.8852 - val_accuracy: 0.2772\n",
      "Epoch 2/50\n",
      "47500/47500 [==============================] - 47s 988us/sample - loss: 1.6220 - accuracy: 0.3876 - val_loss: 1.4288 - val_accuracy: 0.4816\n",
      "Epoch 3/50\n",
      "47500/47500 [==============================] - 47s 982us/sample - loss: 1.3759 - accuracy: 0.5023 - val_loss: 1.4593 - val_accuracy: 0.4960\n",
      "Epoch 4/50\n",
      "47500/47500 [==============================] - 47s 980us/sample - loss: 1.2335 - accuracy: 0.5601 - val_loss: 1.2034 - val_accuracy: 0.5648\n",
      "Epoch 5/50\n",
      "47500/47500 [==============================] - 47s 980us/sample - loss: 1.1402 - accuracy: 0.5984 - val_loss: 1.1606 - val_accuracy: 0.5868\n",
      "Epoch 6/50\n",
      "47500/47500 [==============================] - 47s 980us/sample - loss: 1.0562 - accuracy: 0.6335 - val_loss: 1.0754 - val_accuracy: 0.6092\n",
      "Epoch 7/50\n",
      "47500/47500 [==============================] - 47s 982us/sample - loss: 0.9875 - accuracy: 0.6547 - val_loss: 1.0486 - val_accuracy: 0.6468\n",
      "Epoch 8/50\n",
      "47500/47500 [==============================] - 47s 989us/sample - loss: 0.9227 - accuracy: 0.6795 - val_loss: 1.0317 - val_accuracy: 0.6444\n",
      "Epoch 9/50\n",
      "47500/47500 [==============================] - 47s 984us/sample - loss: 0.8645 - accuracy: 0.7005 - val_loss: 1.0826 - val_accuracy: 0.6408\n",
      "Epoch 10/50\n",
      "47500/47500 [==============================] - 47s 996us/sample - loss: 0.8069 - accuracy: 0.7237 - val_loss: 1.0590 - val_accuracy: 0.6532\n",
      "Epoch 11/50\n",
      "47500/47500 [==============================] - 47s 985us/sample - loss: 0.7569 - accuracy: 0.7387 - val_loss: 1.0518 - val_accuracy: 0.6640\n",
      "Epoch 12/50\n",
      "47500/47500 [==============================] - 47s 980us/sample - loss: 0.7119 - accuracy: 0.7559 - val_loss: 1.0726 - val_accuracy: 0.6544\n",
      "Epoch 13/50\n",
      "47500/47500 [==============================] - 47s 993us/sample - loss: 0.6558 - accuracy: 0.7743 - val_loss: 1.1052 - val_accuracy: 0.6644\n",
      "Epoch 14/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.6175 - accuracy: 0.7863 - val_loss: 1.1252 - val_accuracy: 0.6476\n",
      "Epoch 15/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.5781 - accuracy: 0.8000 - val_loss: 1.1324 - val_accuracy: 0.6684\n",
      "Epoch 16/50\n",
      "47500/47500 [==============================] - 47s 996us/sample - loss: 0.5501 - accuracy: 0.8119 - val_loss: 1.1940 - val_accuracy: 0.6524\n",
      "Epoch 17/50\n",
      "47500/47500 [==============================] - 47s 981us/sample - loss: 0.5101 - accuracy: 0.8255 - val_loss: 1.1499 - val_accuracy: 0.6672\n",
      "Epoch 18/50\n",
      "47500/47500 [==============================] - 46s 977us/sample - loss: 0.4839 - accuracy: 0.8336 - val_loss: 1.2364 - val_accuracy: 0.6628\n",
      "Epoch 19/50\n",
      "47500/47500 [==============================] - 47s 997us/sample - loss: 0.4612 - accuracy: 0.8435 - val_loss: 1.2677 - val_accuracy: 0.6780\n",
      "Epoch 20/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.4422 - accuracy: 0.8499 - val_loss: 1.2680 - val_accuracy: 0.6624\n",
      "Epoch 21/50\n",
      "47500/47500 [==============================] - 47s 980us/sample - loss: 0.3987 - accuracy: 0.8643 - val_loss: 1.3780 - val_accuracy: 0.6652\n",
      "Epoch 22/50\n",
      "47500/47500 [==============================] - 47s 991us/sample - loss: 0.3774 - accuracy: 0.8714 - val_loss: 1.2768 - val_accuracy: 0.6668\n",
      "Epoch 23/50\n",
      "47500/47500 [==============================] - 47s 996us/sample - loss: 0.3664 - accuracy: 0.8750 - val_loss: 1.4799 - val_accuracy: 0.6560\n",
      "Epoch 24/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.3462 - accuracy: 0.8836 - val_loss: 1.4917 - val_accuracy: 0.6644\n",
      "Epoch 25/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.3464 - accuracy: 0.8845 - val_loss: 1.3822 - val_accuracy: 0.6700\n",
      "Epoch 26/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.3145 - accuracy: 0.8941 - val_loss: 1.5728 - val_accuracy: 0.6664\n",
      "Epoch 27/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.3094 - accuracy: 0.8976 - val_loss: 1.5392 - val_accuracy: 0.6692\n",
      "Epoch 28/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.2814 - accuracy: 0.9072 - val_loss: 1.6785 - val_accuracy: 0.6520\n",
      "Epoch 29/50\n",
      "47500/47500 [==============================] - 47s 997us/sample - loss: 0.2949 - accuracy: 0.9029 - val_loss: 1.4470 - val_accuracy: 0.6600\n",
      "Epoch 30/50\n",
      "47500/47500 [==============================] - 46s 969us/sample - loss: 0.2636 - accuracy: 0.9129 - val_loss: 1.8834 - val_accuracy: 0.6544\n",
      "Epoch 31/50\n",
      "47500/47500 [==============================] - 46s 966us/sample - loss: 0.2752 - accuracy: 0.9102 - val_loss: 1.6995 - val_accuracy: 0.6632\n",
      "Epoch 32/50\n",
      "47500/47500 [==============================] - 46s 975us/sample - loss: 0.2605 - accuracy: 0.9148 - val_loss: 1.6584 - val_accuracy: 0.6520\n",
      "Epoch 33/50\n",
      "47500/47500 [==============================] - 46s 971us/sample - loss: 0.2485 - accuracy: 0.9186 - val_loss: 1.7621 - val_accuracy: 0.6616\n",
      "Epoch 34/50\n",
      "47500/47500 [==============================] - 46s 966us/sample - loss: 0.2400 - accuracy: 0.9217 - val_loss: 1.7688 - val_accuracy: 0.6448\n",
      "Epoch 35/50\n",
      "47500/47500 [==============================] - 46s 970us/sample - loss: 0.2221 - accuracy: 0.9285 - val_loss: 1.7554 - val_accuracy: 0.6560\n",
      "Epoch 36/50\n",
      "47500/47500 [==============================] - 46s 966us/sample - loss: 0.2197 - accuracy: 0.9289 - val_loss: 1.8082 - val_accuracy: 0.6648\n",
      "Epoch 37/50\n",
      "47500/47500 [==============================] - 46s 960us/sample - loss: 0.2109 - accuracy: 0.9321 - val_loss: 1.7603 - val_accuracy: 0.6536\n",
      "Epoch 38/50\n",
      "47500/47500 [==============================] - 46s 962us/sample - loss: 0.2072 - accuracy: 0.9345 - val_loss: 1.9208 - val_accuracy: 0.6664\n",
      "Epoch 39/50\n",
      "47500/47500 [==============================] - 45s 957us/sample - loss: 0.1985 - accuracy: 0.9362 - val_loss: 1.9421 - val_accuracy: 0.6564\n",
      "Epoch 40/50\n",
      "47500/47500 [==============================] - 45s 956us/sample - loss: 0.2217 - accuracy: 0.9315 - val_loss: 1.8528 - val_accuracy: 0.6460\n",
      "Epoch 41/50\n",
      "47500/47500 [==============================] - 45s 958us/sample - loss: 0.1965 - accuracy: 0.9384 - val_loss: 1.9665 - val_accuracy: 0.6636\n",
      "Epoch 42/50\n",
      "47500/47500 [==============================] - 46s 967us/sample - loss: 0.1878 - accuracy: 0.9405 - val_loss: 1.9334 - val_accuracy: 0.6520\n",
      "Epoch 43/50\n",
      "47500/47500 [==============================] - 45s 955us/sample - loss: 0.1896 - accuracy: 0.9400 - val_loss: 1.9246 - val_accuracy: 0.6536\n",
      "Epoch 44/50\n",
      "47500/47500 [==============================] - 45s 957us/sample - loss: 0.1887 - accuracy: 0.9411 - val_loss: 2.0312 - val_accuracy: 0.6600\n",
      "Epoch 45/50\n",
      "47500/47500 [==============================] - 46s 960us/sample - loss: 0.1989 - accuracy: 0.9391 - val_loss: 2.0009 - val_accuracy: 0.6552\n",
      "Epoch 46/50\n",
      "47500/47500 [==============================] - 46s 968us/sample - loss: 0.1863 - accuracy: 0.9432 - val_loss: 2.0208 - val_accuracy: 0.6620\n",
      "Epoch 47/50\n",
      "47500/47500 [==============================] - 46s 958us/sample - loss: 0.1974 - accuracy: 0.9414 - val_loss: 1.9387 - val_accuracy: 0.6580\n",
      "Epoch 48/50\n",
      "47500/47500 [==============================] - 46s 960us/sample - loss: 0.1789 - accuracy: 0.9461 - val_loss: 1.9801 - val_accuracy: 0.6556\n",
      "Epoch 49/50\n",
      "47500/47500 [==============================] - 45s 958us/sample - loss: 0.1709 - accuracy: 0.9489 - val_loss: 2.1148 - val_accuracy: 0.6416\n",
      "Epoch 50/50\n",
      "47500/47500 [==============================] - 46s 959us/sample - loss: 0.2018 - accuracy: 0.9415 - val_loss: 2.0406 - val_accuracy: 0.6616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a6a802ba8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn.fit(X_train, y_train, epochs=50, validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Model is not generalizing for validation set -- accuracy is stuck below 0.68. On training test accuracy is about 0.95, which is acceptable (for now).\n",
    "\n",
    "Next step: regularization, providing more training examples (data augmentation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN model with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn_reg = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn_reg.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3),\n",
    "                                 kernel_regularizer=regularizers.l2(0.01)))\n",
    "simple_cnn_reg.add(layers.MaxPooling2D((2, 2)))\n",
    "simple_cnn_reg.add(layers.Conv2D(64, (3, 3), activation='relu',\n",
    "                                 kernel_regularizer=regularizers.l2(0.01)))\n",
    "simple_cnn_reg.add(layers.MaxPooling2D((2, 2)))\n",
    "simple_cnn_reg.add(layers.Conv2D(128, (3, 3), activation='relu',\n",
    "                                 kernel_regularizer=regularizers.l2(0.01)))\n",
    "simple_cnn_reg.add(layers.Flatten())\n",
    "simple_cnn_reg.add(layers.Dense(64, activation='relu',\n",
    "                                kernel_regularizer=regularizers.l2(0.01)))\n",
    "simple_cnn_reg.add(layers.Dense(64, activation='relu',\n",
    "                                kernel_regularizer=regularizers.l2(0.01)))\n",
    "simple_cnn_reg.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 229,194\n",
      "Trainable params: 229,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_cnn_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn_reg.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 2.7760 - accuracy: 0.4173 - val_loss: 2.0429 - val_accuracy: 0.4916\n",
      "Epoch 2/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.7145 - accuracy: 0.5521 - val_loss: 1.4885 - val_accuracy: 0.5924\n",
      "Epoch 3/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.4325 - accuracy: 0.6025 - val_loss: 1.3738 - val_accuracy: 0.6140\n",
      "Epoch 4/50\n",
      "47500/47500 [==============================] - 50s 1ms/sample - loss: 1.3331 - accuracy: 0.6229 - val_loss: 1.2841 - val_accuracy: 0.6340\n",
      "Epoch 5/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.2922 - accuracy: 0.6376 - val_loss: 1.3556 - val_accuracy: 0.6148\n",
      "Epoch 6/50\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 1.2697 - accuracy: 0.6427 - val_loss: 1.3215 - val_accuracy: 0.6320\n",
      "Epoch 7/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.2562 - accuracy: 0.6485 - val_loss: 1.2264 - val_accuracy: 0.6572\n",
      "Epoch 8/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.2361 - accuracy: 0.6545 - val_loss: 1.2078 - val_accuracy: 0.6572\n",
      "Epoch 9/50\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 1.2273 - accuracy: 0.6566 - val_loss: 1.2070 - val_accuracy: 0.6628\n",
      "Epoch 10/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.2174 - accuracy: 0.6582 - val_loss: 1.3053 - val_accuracy: 0.6216\n",
      "Epoch 11/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.1996 - accuracy: 0.6638 - val_loss: 1.2386 - val_accuracy: 0.6528\n",
      "Epoch 12/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.2011 - accuracy: 0.6652 - val_loss: 1.2463 - val_accuracy: 0.6416\n",
      "Epoch 13/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.1996 - accuracy: 0.6650 - val_loss: 1.2044 - val_accuracy: 0.6624\n",
      "Epoch 14/50\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 1.1919 - accuracy: 0.6708 - val_loss: 1.2285 - val_accuracy: 0.6504\n",
      "Epoch 15/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.1849 - accuracy: 0.6708 - val_loss: 1.2042 - val_accuracy: 0.6556\n",
      "Epoch 16/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.1805 - accuracy: 0.6715 - val_loss: 1.2285 - val_accuracy: 0.6564\n",
      "Epoch 17/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.1798 - accuracy: 0.6726 - val_loss: 1.1697 - val_accuracy: 0.6772\n",
      "Epoch 18/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.1726 - accuracy: 0.6771 - val_loss: 1.1544 - val_accuracy: 0.6832\n",
      "Epoch 19/50\n",
      "47500/47500 [==============================] - 47s 997us/sample - loss: 1.1663 - accuracy: 0.6762 - val_loss: 1.2510 - val_accuracy: 0.6512\n",
      "Epoch 20/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.1642 - accuracy: 0.6766 - val_loss: 1.2366 - val_accuracy: 0.6424\n",
      "Epoch 21/50\n",
      "47500/47500 [==============================] - 46s 976us/sample - loss: 1.1598 - accuracy: 0.6785 - val_loss: 1.1596 - val_accuracy: 0.6680\n",
      "Epoch 22/50\n",
      "47500/47500 [==============================] - 50s 1ms/sample - loss: 1.1570 - accuracy: 0.6800 - val_loss: 1.2240 - val_accuracy: 0.6620\n",
      "Epoch 23/50\n",
      "47500/47500 [==============================] - 47s 992us/sample - loss: 1.1595 - accuracy: 0.6798 - val_loss: 1.1771 - val_accuracy: 0.6720\n",
      "Epoch 24/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.1530 - accuracy: 0.6832 - val_loss: 1.1843 - val_accuracy: 0.6672\n",
      "Epoch 25/50\n",
      "47500/47500 [==============================] - 46s 974us/sample - loss: 1.1514 - accuracy: 0.6817 - val_loss: 1.2274 - val_accuracy: 0.6436\n",
      "Epoch 26/50\n",
      "47500/47500 [==============================] - 46s 974us/sample - loss: 1.1532 - accuracy: 0.6805 - val_loss: 1.2569 - val_accuracy: 0.6420\n",
      "Epoch 27/50\n",
      "47500/47500 [==============================] - 46s 975us/sample - loss: 1.1441 - accuracy: 0.6854 - val_loss: 1.1908 - val_accuracy: 0.6636\n",
      "Epoch 28/50\n",
      "47500/47500 [==============================] - 47s 980us/sample - loss: 1.1457 - accuracy: 0.6824 - val_loss: 1.2801 - val_accuracy: 0.6424\n",
      "Epoch 29/50\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 1.1426 - accuracy: 0.6854 - val_loss: 1.1984 - val_accuracy: 0.6732\n",
      "Epoch 30/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.1393 - accuracy: 0.6834 - val_loss: 1.2077 - val_accuracy: 0.6568\n",
      "Epoch 31/50\n",
      "47500/47500 [==============================] - 46s 973us/sample - loss: 1.1477 - accuracy: 0.6809 - val_loss: 1.1648 - val_accuracy: 0.6668\n",
      "Epoch 32/50\n",
      "47500/47500 [==============================] - 47s 988us/sample - loss: 1.1305 - accuracy: 0.6864 - val_loss: 1.1931 - val_accuracy: 0.6536\n",
      "Epoch 33/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.1429 - accuracy: 0.6848 - val_loss: 1.3261 - val_accuracy: 0.6152\n",
      "Epoch 34/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.1345 - accuracy: 0.6861 - val_loss: 1.2956 - val_accuracy: 0.6288\n",
      "Epoch 35/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.1336 - accuracy: 0.6859 - val_loss: 1.1517 - val_accuracy: 0.6784\n",
      "Epoch 36/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.1365 - accuracy: 0.6890 - val_loss: 1.1560 - val_accuracy: 0.6844\n",
      "Epoch 37/50\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 1.1329 - accuracy: 0.6880 - val_loss: 1.1336 - val_accuracy: 0.6968\n",
      "Epoch 38/50\n",
      "47500/47500 [==============================] - 50s 1ms/sample - loss: 1.1285 - accuracy: 0.6887 - val_loss: 1.2197 - val_accuracy: 0.6588\n",
      "Epoch 39/50\n",
      "47500/47500 [==============================] - 50s 1ms/sample - loss: 1.1299 - accuracy: 0.6879 - val_loss: 1.1190 - val_accuracy: 0.6840\n",
      "Epoch 40/50\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 1.1269 - accuracy: 0.6874 - val_loss: 1.1336 - val_accuracy: 0.6756\n",
      "Epoch 41/50\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 1.1346 - accuracy: 0.6861 - val_loss: 1.1200 - val_accuracy: 0.6896\n",
      "Epoch 42/50\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 1.1224 - accuracy: 0.6902 - val_loss: 1.1273 - val_accuracy: 0.6944\n",
      "Epoch 43/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.1191 - accuracy: 0.6921 - val_loss: 1.1925 - val_accuracy: 0.6672\n",
      "Epoch 44/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.1264 - accuracy: 0.6926 - val_loss: 1.0986 - val_accuracy: 0.6968\n",
      "Epoch 45/50\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 1.1221 - accuracy: 0.6928 - val_loss: 1.2069 - val_accuracy: 0.6612\n",
      "Epoch 46/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.1304 - accuracy: 0.6875 - val_loss: 1.1352 - val_accuracy: 0.6880\n",
      "Epoch 47/50\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 1.1218 - accuracy: 0.6912 - val_loss: 1.1814 - val_accuracy: 0.6724\n",
      "Epoch 48/50\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 1.1213 - accuracy: 0.6902 - val_loss: 1.1396 - val_accuracy: 0.6856\n",
      "Epoch 49/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.1206 - accuracy: 0.6911 - val_loss: 1.2030 - val_accuracy: 0.6636\n",
      "Epoch 50/50\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 1.1261 - accuracy: 0.6919 - val_loss: 1.2235 - val_accuracy: 0.6540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a6b434be0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn_reg.fit(X_train, y_train, epochs=50, validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Model is generalizing better, but it's also much weaker - accuracy on validation set is on the same level as before, it only got worse on training set.\n",
    "\n",
    "Next step: adding more layers, lowering regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeper CNN with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_cnn_reg = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_cnn_reg.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3),\n",
    "                                 kernel_regularizer=regularizers.l2(0.001)))\n",
    "deep_cnn_reg.add(layers.MaxPooling2D((2, 2)))\n",
    "deep_cnn_reg.add(layers.Conv2D(64, (3, 3), activation='relu',\n",
    "                                 kernel_regularizer=regularizers.l2(0.001)))\n",
    "deep_cnn_reg.add(layers.MaxPooling2D((2, 2)))\n",
    "deep_cnn_reg.add(layers.Conv2D(128, (3, 3), activation='relu',\n",
    "                                 kernel_regularizer=regularizers.l2(0.001)))\n",
    "deep_cnn_reg.add(layers.Flatten())\n",
    "deep_cnn_reg.add(layers.Dense(128, activation='relu',\n",
    "                                kernel_regularizer=regularizers.l2(0.01)))\n",
    "deep_cnn_reg.add(layers.Dense(128, activation='relu',\n",
    "                                kernel_regularizer=regularizers.l2(0.01)))\n",
    "deep_cnn_reg.add(layers.Dense(128, activation='relu',\n",
    "                                kernel_regularizer=regularizers.l2(0.01)))\n",
    "deep_cnn_reg.add(layers.Dense(64, activation='relu',\n",
    "                                kernel_regularizer=regularizers.l2(0.01)))\n",
    "deep_cnn_reg.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 397,450\n",
      "Trainable params: 397,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_cnn_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_cnn_reg.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/50\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 2.9819 - accuracy: 0.4291 - val_loss: 1.8353 - val_accuracy: 0.5268\n",
      "Epoch 2/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.5820 - accuracy: 0.5624 - val_loss: 1.6018 - val_accuracy: 0.5352\n",
      "Epoch 3/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.3439 - accuracy: 0.6112 - val_loss: 1.3048 - val_accuracy: 0.6240\n",
      "Epoch 4/50\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 1.2498 - accuracy: 0.6448 - val_loss: 1.2420 - val_accuracy: 0.6504\n",
      "Epoch 5/50\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 1.1914 - accuracy: 0.6676 - val_loss: 1.1878 - val_accuracy: 0.6680\n",
      "Epoch 6/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.1519 - accuracy: 0.6868 - val_loss: 1.1541 - val_accuracy: 0.6848\n",
      "Epoch 7/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.1200 - accuracy: 0.6961 - val_loss: 1.2215 - val_accuracy: 0.6636\n",
      "Epoch 8/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.0927 - accuracy: 0.7055 - val_loss: 1.1954 - val_accuracy: 0.6756\n",
      "Epoch 9/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.0810 - accuracy: 0.7126 - val_loss: 1.0783 - val_accuracy: 0.7072\n",
      "Epoch 10/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.0508 - accuracy: 0.7239 - val_loss: 1.2903 - val_accuracy: 0.6556\n",
      "Epoch 11/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.0417 - accuracy: 0.7288 - val_loss: 1.1562 - val_accuracy: 0.6992\n",
      "Epoch 12/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.0311 - accuracy: 0.7331 - val_loss: 1.0958 - val_accuracy: 0.6984\n",
      "Epoch 13/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 1.0169 - accuracy: 0.7391 - val_loss: 1.1185 - val_accuracy: 0.7060\n",
      "Epoch 14/50\n",
      "47500/47500 [==============================] - 51s 1ms/sample - loss: 1.0078 - accuracy: 0.7452 - val_loss: 1.1136 - val_accuracy: 0.7144\n",
      "Epoch 15/50\n",
      "47500/47500 [==============================] - 52s 1ms/sample - loss: 0.9943 - accuracy: 0.7498 - val_loss: 1.0821 - val_accuracy: 0.7228\n",
      "Epoch 16/50\n",
      "47500/47500 [==============================] - 51s 1ms/sample - loss: 0.9864 - accuracy: 0.7528 - val_loss: 1.0976 - val_accuracy: 0.7224\n",
      "Epoch 17/50\n",
      "47500/47500 [==============================] - 51s 1ms/sample - loss: 0.9783 - accuracy: 0.7549 - val_loss: 1.1237 - val_accuracy: 0.7144\n",
      "Epoch 18/50\n",
      "47500/47500 [==============================] - 50s 1ms/sample - loss: 0.9749 - accuracy: 0.7583 - val_loss: 1.1611 - val_accuracy: 0.7044\n",
      "Epoch 19/50\n",
      "47500/47500 [==============================] - 50s 1ms/sample - loss: 0.9682 - accuracy: 0.7613 - val_loss: 1.0878 - val_accuracy: 0.7272\n",
      "Epoch 20/50\n",
      "47500/47500 [==============================] - 50s 1ms/sample - loss: 0.9643 - accuracy: 0.7626 - val_loss: 1.1431 - val_accuracy: 0.7036\n",
      "Epoch 21/50\n",
      "47500/47500 [==============================] - 50s 1ms/sample - loss: 0.9603 - accuracy: 0.7655 - val_loss: 1.0643 - val_accuracy: 0.7368\n",
      "Epoch 22/50\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 0.9547 - accuracy: 0.7681 - val_loss: 1.0814 - val_accuracy: 0.7256\n",
      "Epoch 23/50\n",
      "47500/47500 [==============================] - 50s 1ms/sample - loss: 0.9580 - accuracy: 0.7678 - val_loss: 1.0304 - val_accuracy: 0.7480\n",
      "Epoch 24/50\n",
      "47500/47500 [==============================] - 50s 1ms/sample - loss: 0.9465 - accuracy: 0.7726 - val_loss: 1.0410 - val_accuracy: 0.7436\n",
      "Epoch 25/50\n",
      "47500/47500 [==============================] - 50s 1ms/sample - loss: 0.9414 - accuracy: 0.7723 - val_loss: 1.0645 - val_accuracy: 0.7384\n",
      "Epoch 26/50\n",
      "47500/47500 [==============================] - 50s 1ms/sample - loss: 0.9358 - accuracy: 0.7769 - val_loss: 1.1517 - val_accuracy: 0.7084\n",
      "Epoch 27/50\n",
      "47500/47500 [==============================] - 50s 1ms/sample - loss: 0.9344 - accuracy: 0.7757 - val_loss: 1.0932 - val_accuracy: 0.7244\n",
      "Epoch 28/50\n",
      "47500/47500 [==============================] - 50s 1ms/sample - loss: 0.9284 - accuracy: 0.7791 - val_loss: 1.0424 - val_accuracy: 0.7388\n",
      "Epoch 29/50\n",
      "47500/47500 [==============================] - 50s 1ms/sample - loss: 0.9285 - accuracy: 0.7797 - val_loss: 1.0943 - val_accuracy: 0.7240\n",
      "Epoch 30/50\n",
      "47500/47500 [==============================] - 50s 1ms/sample - loss: 0.9218 - accuracy: 0.7819 - val_loss: 1.0576 - val_accuracy: 0.7352\n",
      "Epoch 31/50\n",
      "47500/47500 [==============================] - 50s 1ms/sample - loss: 0.9179 - accuracy: 0.7820 - val_loss: 1.1312 - val_accuracy: 0.7160\n",
      "Epoch 32/50\n",
      "47500/47500 [==============================] - 50s 1ms/sample - loss: 0.9234 - accuracy: 0.7814 - val_loss: 1.1507 - val_accuracy: 0.7140\n",
      "Epoch 33/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.9202 - accuracy: 0.7812 - val_loss: 1.0972 - val_accuracy: 0.7268\n",
      "Epoch 34/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.9116 - accuracy: 0.7870 - val_loss: 1.1177 - val_accuracy: 0.7212\n",
      "Epoch 35/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.9080 - accuracy: 0.7889 - val_loss: 1.1200 - val_accuracy: 0.7100\n",
      "Epoch 36/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.9060 - accuracy: 0.7875 - val_loss: 1.0688 - val_accuracy: 0.7396\n",
      "Epoch 37/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.9121 - accuracy: 0.7864 - val_loss: 1.0788 - val_accuracy: 0.7368\n",
      "Epoch 38/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.9098 - accuracy: 0.7875 - val_loss: 1.0531 - val_accuracy: 0.7404\n",
      "Epoch 39/50\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 0.9037 - accuracy: 0.7910 - val_loss: 1.0882 - val_accuracy: 0.7336\n",
      "Epoch 40/50\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 0.9051 - accuracy: 0.7893 - val_loss: 1.0763 - val_accuracy: 0.7400\n",
      "Epoch 41/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.8908 - accuracy: 0.7942 - val_loss: 1.0542 - val_accuracy: 0.7356\n",
      "Epoch 42/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.8962 - accuracy: 0.7918 - val_loss: 1.0523 - val_accuracy: 0.7436\n",
      "Epoch 43/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.8919 - accuracy: 0.7944 - val_loss: 1.0698 - val_accuracy: 0.7288\n",
      "Epoch 44/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.8961 - accuracy: 0.7934 - val_loss: 1.0924 - val_accuracy: 0.7300\n",
      "Epoch 45/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.8877 - accuracy: 0.7978 - val_loss: 1.0388 - val_accuracy: 0.7428\n",
      "Epoch 46/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.8905 - accuracy: 0.7945 - val_loss: 1.1049 - val_accuracy: 0.7244\n",
      "Epoch 47/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.8812 - accuracy: 0.7990 - val_loss: 1.1324 - val_accuracy: 0.7136\n",
      "Epoch 48/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.8922 - accuracy: 0.7953 - val_loss: 1.0758 - val_accuracy: 0.7384\n",
      "Epoch 49/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.8949 - accuracy: 0.7944 - val_loss: 1.1046 - val_accuracy: 0.7388\n",
      "Epoch 50/50\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.8918 - accuracy: 0.7969 - val_loss: 1.0422 - val_accuracy: 0.7524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1aa53868d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_cnn_reg.fit(X_train, y_train, epochs=50, validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Accuracy on validation set is much better than before, but there is again problem with overfitting.\n",
    "\n",
    "Next step: data normalization and augmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-cpu)",
   "language": "python",
   "name": "ml-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
